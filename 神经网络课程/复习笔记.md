# 神经网络

![img](https://rossetta-typora-imgsubmit.oss-cn-hangzhou.aliyuncs.com/img/EB6F7B414D66780127A0A30EB098BEC8.jpg)

## 一、人工神经元

### 1、人工神经元的功能

![image-20211219213601231](https://rossetta-typora-imgsubmit.oss-cn-hangzhou.aliyuncs.com/img/image-20211219213601231.png)

* 从树突（dendrite）收集信号
* 通过轴突（axon）发送电活动脉冲给上千个分支
* 在分支末端，通过突触（synapse）转换信号给另一个神经元的树突
* 神经元在信号传递活动时作用

![image-20211219220345447](https://rossetta-typora-imgsubmit.oss-cn-hangzhou.aliyuncs.com/img/image-20211219220345447.png)

### 2、人工神经元和生物神经元的关系

输入连接  神经元接收器

节点、单元  仿真神经元胞体

| 人工神经元 | 生物神经元         |
| ---------- | ------------------ |
| 输入连接   | 接收器（树突）     |
| 节点       | 模拟神经元胞体     |
| 输出连接   | 发射器（轴突）     |
| 激活函数   | 使用阈值或偏差     |
| w          | 充当突触连接的权值 |
| b          | 神经元的偏置参数   |

![image-20211219221953348](https://rossetta-typora-imgsubmit.oss-cn-hangzhou.aliyuncs.com/img/image-20211219221953348.png)

### 3、激活函数

**阶跃函数**

* 阶跃函数

$$
y = f(x) = \begin{cases} 1, x > 0 \\ -1, x \leq 0 \end{cases}
$$

* 线性函数

$$
f(x) = kx + b
$$

* sigmoid 函数

$$
f(x) = \frac {1}{1+e^{-z}}
$$

![image-20211219222751615](https://rossetta-typora-imgsubmit.oss-cn-hangzhou.aliyuncs.com/img/image-20211219222751615.png)

* Leaky Relu 函数

$$
f(x) = max(0.01x, x)
$$

![image-20211219222725872](https://rossetta-typora-imgsubmit.oss-cn-hangzhou.aliyuncs.com/img/image-20211219222725872.png)

----------

## 二、人工神经网络

### 1、人工神经网络

> 从训练和损失中学习

训练（trial）：通过给定的输入计算输出函数

评估（evaluate）：通过比较实际结果和期望的结果来评估输出

调整（adjust）：调整权重

#### 结构

输入层 -> 隐藏层 -> 输出层

#### 感知机

> 输出值只有0和1

$$
y = hardlim(wx + b)
$$

其中，hardlim是硬极限函数

![image-20211219224310047](https://rossetta-typora-imgsubmit.oss-cn-hangzhou.aliyuncs.com/img/image-20211219224310047.png)

#### 单层简单神经网络的局限性

**只能模拟简单的线性函数，而大多数复杂的非线性函数无法模拟**

#### 多层前馈网络

* 隐藏层允许线性函数的联合
* 非线性激活函数显示的属性更接近真实神经元

--------

### 2、学习

#### 监督学习

回归：用训练数据预测输出值

分类：对输出结果进行分组

##### **逻辑回归**

通过sigmoid将线性模型转为分类模型 
$$
h_\theta(x) = \theta^Tx + \theta_0 = z \to sigmoid(z) = result = \begin{cases} 1, z > 0 \\ 0, z < 0 \end{cases}
$$
其中，损失函数为**交叉熵损失函数**
$$
J(\theta) = -\frac 1m [\sum _{i=1}^m y^{(i)}logh_\theta (x^{(i)}) + (1-y^{(i)}) log(1-h_\theta(x^{(i)}))]
$$

##### 支持向量机

> 定义再特征空间上的**间隔最大**的线性分类器，学习策略为间隔最大化

<img src="https://rossetta-typora-imgsubmit.oss-cn-hangzhou.aliyuncs.com/img/image-20211220121844759.png" alt="image-20211220121844759" style="zoom:50%;" />

其中，$H_3$使得以最大间隔将两类分开。

#### 无监督学习

> 如果训练集给定了标签，则是监督学习，如果没有给定标签，则是无监督学习

* K-means聚类算法
* 最大主成分分析（PCA）
* ……

---------

### 3、Rosenblatt 感知机

![image-20211220123026192](https://rossetta-typora-imgsubmit.oss-cn-hangzhou.aliyuncs.com/img/image-20211220123026192.png)

**要满足$y(wx+b) \geq 0$，否则即预测结果和标签异号，需要根据公式调整w和b**

------

### 4、反向传播算法

![image-20211220211029816](https://rossetta-typora-imgsubmit.oss-cn-hangzhou.aliyuncs.com/img/image-20211220211029816.png)

---------

## 三、优化器

### 1、损失函数

**损失函数（Loss function）和代价函数（Cost function）**的区别

* 损失函数基于单个例子，而代价函数是整个训练集的平均误差
* 回归问题常用MAE（平均绝对误差），分类问题常用Cross-entropy（交叉熵误差函数）

$$
MAE = \frac 1N \sum_{i=1}^N |y^{(i)} - f(x^{(i)})| \\
Cross\space entropy = -\frac 1m [\sum _{i=1}^m y^{(i)}logh_\theta (x^{(i)}) + (1-y^{(i)}) log(1-h_\theta(x^{(i)}))]
$$

其中$y$为真实分布可能性，$h_\theta(x)$为训练分布可能性。

#### 目标函数（Object Function）

$$
min \to L(\theta) = \frac 1n \sum_{i=1}^n Loss(f_\theta(x_i), y_i) 
$$

---------

### 2、梯度下降

#### 方向导数

**方向导数用于研究函数沿各个不同的方向时函数的变化率，是<u>标量</u>**

![image-20211220221536406](https://rossetta-typora-imgsubmit.oss-cn-hangzhou.aliyuncs.com/img/image-20211220221536406.png)

梯度定义的超平面近似公式如下：

![image-20211220221625900](https://rossetta-typora-imgsubmit.oss-cn-hangzhou.aliyuncs.com/img/image-20211220221625900.png)

#### 梯度

**梯度的方向是方向导数中取到最大值的方向，梯度的模是最大方向导数**

梯度是一个<u>**向量**</u>，表示为：
$$
grad(f) = (\frac {\partial f}{\partial x_0}, ... ,\frac {\partial f}{\partial x_j}, ..., \frac {\partial f}{\partial x_n})
$$

#### 梯度下降

$$
x_{t+1} = x_t - lr * \nabla f(x_t)
$$

#### 学习率的影响

![image-20211220222610300](https://rossetta-typora-imgsubmit.oss-cn-hangzhou.aliyuncs.com/img/image-20211220222610300.png)

学习率过大：易损失爆炸；易振荡

学习率过小：易过拟合；收敛慢

#### 牛顿法（适用于一阶）

在极小点附近用函数的二阶泰勒多项式近似代替目标，从而求得目标函数的极小点的近似值

![image-20211220222915424](https://rossetta-typora-imgsubmit.oss-cn-hangzhou.aliyuncs.com/img/image-20211220222915424.png)

最终满足$f'(x_t) \leq \epsilon$

缺点：

* 需要计算时间为$O(M^3)$，损失时间性能
* 对于高维不稳定

---------

### 3、随机梯度下降

![image-20211220223659246](https://rossetta-typora-imgsubmit.oss-cn-hangzhou.aliyuncs.com/img/image-20211220223659246.png)

![image-20211220223924393](https://rossetta-typora-imgsubmit.oss-cn-hangzhou.aliyuncs.com/img/image-20211220223924393.png)

![image-20211220224042595](https://rossetta-typora-imgsubmit.oss-cn-hangzhou.aliyuncs.com/img/image-20211220224042595.png)

![image-20211220224845151](https://rossetta-typora-imgsubmit.oss-cn-hangzhou.aliyuncs.com/img/image-20211220224845151.png)

![image-20211220224914233](https://rossetta-typora-imgsubmit.oss-cn-hangzhou.aliyuncs.com/img/image-20211220224914233.png)

![image-20211220225006286](https://rossetta-typora-imgsubmit.oss-cn-hangzhou.aliyuncs.com/img/image-20211220225006286.png)

----------

### 4、更多优化器

![image-20211220225107266](https://rossetta-typora-imgsubmit.oss-cn-hangzhou.aliyuncs.com/img/image-20211220225107266.png)

#### momentum（动量法）

$$
v_t = \alpha v_{t-1} - \eta\nabla f(x_{t-1}) \\
x_t = x_{t-1} + v_t
$$

物理意义：一个滚向局部最优点的小球

动量法的优点：增加了一个动量（v），增加了找到全局最优点的可能性增加，可以冲过局部最优点。可能越过目标，但比SGD更快收敛

改进：![image-20211221101828085](https://rossetta-typora-imgsubmit.oss-cn-hangzhou.aliyuncs.com/img/image-20211221101828085.png)

![image-20211221101841291](https://rossetta-typora-imgsubmit.oss-cn-hangzhou.aliyuncs.com/img/image-20211221101841291.png)
$$
v_t = \alpha v_{t-1} - \eta\nabla f(x_{t-1} + \alpha v_{t-1}) \\
x_t = x_{t-1} + v_t
$$

#### AdaGrad

**在每一次迭代时，不同的参数使用不同的学习率**
$$
s_t = s_{t-1} + \nabla f^2(x_t) \\
x_{t+1} = x_t - \frac {\eta}{\sqrt{S_t}+\epsilon} \nabla f(x_t)
$$
优点：梯度较大的地方学习率小，梯度较小的地方学习率大，容易度过平缓地区

缺点：积累的是梯度的平方，到后面变得很大会导致梯度消失

#### rmsprop

**对梯度的平方使用指数加权平均**
$$
s_t = \beta S_{t-1} + (1-\beta)\nabla f^2(x_t) \\
x_{t+1} = x_t - \frac \eta {\sqrt{S_t}+\epsilon} \nabla f(x_t)
$$
$\beta$的作用：

* 对历史梯度与当前梯度进行加权平均
* 减小久远梯度的影响力

----------------------------

## 四、卷积神经网络（CNN）

#### 特征图和感受野

特征图：二维卷积层经计算得出的二维数据可以看作是输入图片在空间域上<u>某一级的特征</u>，又叫做特征图

感受野：与输出有关的输入图片的局部大小

#### 计算特征图的公式

$$
output = \frac {input + 2*padding - kernel\_size}{stride} + 1
$$



#### CNN压缩全连接网络的方式

* 减少了连接的数量
* 权重共享
* 最大池化减少其复杂性

#### LeNet

* 使用卷积层和最大池化层提取特征后用全连接层进行分类
* 开山之作

#### AlexNet

* 浅层神经网络和深层神经网络的分界线

* 激活函数改用ReLU，更简单且在不同初始化方法下更容易训练，防止sigmoid接近0时梯度接近0难以训练
* 采用了dropout来控制全连接层的复杂度

#### VGGNet

* 更小的卷积核（3×3）（1×1），更深的网络，较小的卷积核可以保证在相同感受野的条件下有较深的网络
* 提出了可以重复利用简单块构建模型的思路

#### GoogleNet

* 只有AlexNet模型1/12的参数

* 采用了Inception模块，有4条通道进行级联，通过不同尺寸的卷积和池化来抽取信息，同时用1×1卷积来降低通道数（模型复杂度）

  ![image-20211221175716752](https://rossetta-typora-imgsubmit.oss-cn-hangzhou.aliyuncs.com/img/image-20211221175716752.png)

* 没有全连接层

#### ResNet

* 使用了残差结构，使模型深度大大加深
* 跨层结构保证有效训练
* 深刻影响了后来的模型

----------------

## 五、循环神经网络（RNN）

> 主要用于训练时间序列数据
>
> 时间序列数据采集自不同的时间点，反映了事物随时间变换的状态
>
> 给定一个长度为$T$的时间序列，语言模型计算其序列的概率$p(w_1, w_2, ..., w_T)$

### 1、语言模型的计算

t时刻的序列概率和前t-1时刻的序列概率都相关
$$
P(w_1, w_2, ..., w_T) = \prod_{t=1}^{T} P(w_t | w_1, ..., w_{t-1})
$$
如果一个含有4个词的文本序列：
$$
P(w_1, w_2, w_3, w_4) = P(w_1)P(w_2|w_1)P(w_3|w_1, w_2)P(w_4|w_1, w_2, w_3)
$$
为了防止序列长度增加时，计算和存储多个词出现的概率的复杂度指数级增加的问题。n元语法通过马尔科夫链简化了运算。

**n-1阶马尔可夫链**表示为：
$$
P(w_1, w_2, ..., w_T) \approx \prod_{t=1}^T P(w_t|w_{t-(n-1)}, ..., w_{t-1})
$$
如果n=1、n=2、n=3时，分别称为一元语法、二元语法、三元语法

![image-20211221215654418](https://rossetta-typora-imgsubmit.oss-cn-hangzhou.aliyuncs.com/img/image-20211221215654418.png)

**当n较小时，n元语法往往不准确；当n较大时，n元语法需要计算并存储大量的词频和多词相邻频率。如何平衡这两个问题？**

### 2、循环神经网络

> 并非刚性的记忆所有固定长度的序列，而是通过**隐藏状态**来存储之前时间步的信息

#### 下一时间步的输出状态取决于输入和当前状态的加权和

隐藏层的计算公式为：

![image-20211221221145250](https://rossetta-typora-imgsubmit.oss-cn-hangzhou.aliyuncs.com/img/image-20211221221145250.png)

在时间步t，输出层的计算公式为：

![image-20211221222558558](https://rossetta-typora-imgsubmit.oss-cn-hangzhou.aliyuncs.com/img/image-20211221222558558.png)

引入一个新的权重参数$W_{hh}$，该参数用来描述在当前时间步如何使用上一时间步的**隐藏变量**$H_{t-1}$，该变量也被称为隐藏状态，上式运用了上一步的状态，故为循环神经网络。

![image-20211221222719458](https://rossetta-typora-imgsubmit.oss-cn-hangzhou.aliyuncs.com/img/image-20211221222719458.png)

![image-20211221205105055](https://rossetta-typora-imgsubmit.oss-cn-hangzhou.aliyuncs.com/img/image-20211221205105055.png)

#### 在所有时间步内，有相同的权重，循环神经网络的参数不随时间的增长而增长

![](https://rossetta-typora-imgsubmit.oss-cn-hangzhou.aliyuncs.com/img/image-20211221205633290.png)

![image-20211221222836129](https://rossetta-typora-imgsubmit.oss-cn-hangzhou.aliyuncs.com/img/image-20211221222836129.png)

![image-20211221222956858](https://rossetta-typora-imgsubmit.oss-cn-hangzhou.aliyuncs.com/img/image-20211221222956858.png)

**激活函数常用tanh（双曲正切）**
$$
tanh(x) = \frac {1-exp(-2x)}{1+exp(-2x)}
$$
当输入接近0时，tanh函数接近线性变换。

![img](https://rossetta-typora-imgsubmit.oss-cn-hangzhou.aliyuncs.com/img/3.8_tanh.png)

tanh函数的导数为
$$
tanh'(x) = 1 - tanh^2(x)
$$
![img](https://rossetta-typora-imgsubmit.oss-cn-hangzhou.aliyuncs.com/img/3.8_tanh_grad.png)

![image-20211222230836602](https://rossetta-typora-imgsubmit.oss-cn-hangzhou.aliyuncs.com/img/image-20211222230836602.png)

--------

### 3、经过时间的反向传播

![image-20211222232239927](https://rossetta-typora-imgsubmit.oss-cn-hangzhou.aliyuncs.com/img/image-20211222232239927.png)

其中，W代表的是$W_{hh}$，代表的是上一时间步状态的权重。**E为损失函数。**

#### 梯度的爆炸和消失问题

![image-20211222232643879](https://rossetta-typora-imgsubmit.oss-cn-hangzhou.aliyuncs.com/img/image-20211222232643879.png)

![image-20211223155117850](https://rossetta-typora-imgsubmit.oss-cn-hangzhou.aliyuncs.com/img/image-20211223155117850.png)

由于状态的导数**和先前的状态有关**，当**时间步数T较大或者时间步t较小**时，目标有关隐藏状态的梯度容易出现爆炸或者消失。

![image-20211222233029139](https://rossetta-typora-imgsubmit.oss-cn-hangzhou.aliyuncs.com/img/image-20211222233029139.png)
$$
y_1 = f(1\times1 + 0) \times 1 = 1 \\
y_2 = f(1\times0 + w*y_1) \times 1 = w \\
.\\
.\\
.\\
y_{1000} = w^{999}
$$

-------

### 4、GRU（门控循环神经网络）

> 由于循环神经网络难以解决难捕捉时间序列中时间步距离较大的依赖关系

#### 引入了重置门和更新门

<img src="https://rossetta-typora-imgsubmit.oss-cn-hangzhou.aliyuncs.com/img/image-20211223161814587.png" alt="image-20211223161814587" style="zoom:150%;" />

* 首先，根据隐藏状态计算重置门和更新门，激活函数为sigmoid

![image-20211223161222971](https://rossetta-typora-imgsubmit.oss-cn-hangzhou.aliyuncs.com/img/image-20211223161222971.png)

* 运用**重置门来计算候选隐藏状态**，来控制上一时间步的隐藏状态如何流入当前时间步的候选隐藏状态，其可能包含了时间序列截止上一时间步的的历史状态信息，当$R_t$为0时，表示丢弃了无关的历史信息，激活函数为tanh

![image-20211223161614462](https://rossetta-typora-imgsubmit.oss-cn-hangzhou.aliyuncs.com/img/image-20211223161614462.png)

* 运用**更新门将上一时间步的隐藏状态和当前时间步的候选隐藏状态做组合**，生成当前时间步的隐藏状态，某一时间段如果$Z_t$为1，表示摒弃了隐藏状态，即这段时间内的信息没有流入隐藏状态。换言之，长时间前的状态信息一直被保存

![image-20211223161715988](https://rossetta-typora-imgsubmit.oss-cn-hangzhou.aliyuncs.com/img/image-20211223161715988.png)

#### 小结

- 门控循环神经网络可以更好地捕捉时间序列中时间步距离较大的依赖关系。
- 门控循环单元引入了门的概念，从而修改了循环神经网络中隐藏状态的计算方式。它包括重置门、更新门、候选隐藏状态和隐藏状态。
- 重置门有助于捕捉时间序列里短期的依赖关系。
- 更新门有助于捕捉时间序列里长期的依赖关系。

--------------

### 4、LSTM（长短期记忆）

#### 和普通RNN的不同，LSTM引出了3个门，输入门、输出门和遗忘门，以及和隐藏状态形状相同的记忆细胞

<img src="https://rossetta-typora-imgsubmit.oss-cn-hangzhou.aliyuncs.com/img/image-20211223145029418.png" alt="image-20211223145029418" style="zoom:67%;" />

![image-20211223153011129](https://rossetta-typora-imgsubmit.oss-cn-hangzhou.aliyuncs.com/img/image-20211223153011129.png)

<img src="https://rossetta-typora-imgsubmit.oss-cn-hangzhou.aliyuncs.com/img/image-20211223170143811.png" alt="image-20211223170143811" style="zoom:150%;" />

* 通过上一时间步的隐藏状态计算输入门、输出门和遗忘门，激活函数为sigmoid

![image-20211223164445684](https://rossetta-typora-imgsubmit.oss-cn-hangzhou.aliyuncs.com/img/image-20211223164445684.png)

* 计算候选记忆细胞，和上面三个门类似，但是激活函数是tanh

![image-20211223164835194](https://rossetta-typora-imgsubmit.oss-cn-hangzhou.aliyuncs.com/img/image-20211223164835194.png)

* 通过**遗忘门和输入门的组合**来计算记忆细胞$C_t$

![image-20211223165036338](https://rossetta-typora-imgsubmit.oss-cn-hangzhou.aliyuncs.com/img/image-20211223165036338.png)

遗忘门控制上一时间步的记忆细胞$C_{t-1}$中的信息是否传递到当前时间步；而输入门则控制当前时间步的输入$X_t$通过候选记忆细胞$\widetilde C_t$如何流入当前时间步的记忆细胞。

如果遗忘门一直近似1且输入门一直近似0，$C_t \approx C_{t-1}$。过去的记忆细胞将一直通过时间保存并传递至当前时间步。这个设计可以应对循环神经网络中的梯度衰减问题，并更好地捕捉时间序列中时间步距离较大的依赖关系。11

* 最后，通过**输出门**控制信息从记忆细胞到隐藏状态的流动

![image-20211223170731335](https://rossetta-typora-imgsubmit.oss-cn-hangzhou.aliyuncs.com/img/image-20211223170731335.png)

**当输出门接近1时，记忆细胞的信息将传递给隐藏状态使用，而输出门接近0时，记忆细胞的信息将自己保留**

------------------

#### 小结

- 长短期记忆的隐藏层输出包括隐藏状态和记忆细胞。只有隐藏状态会传递到输出层。
- 长短期记忆的输入门、遗忘门和输出门可以控制信息的流动。
- 长短期记忆可以**应对循环神经网络中的梯度衰减问题**，并更好地捕捉时间序列中时间步距离较大的依赖关系。

### 5、LSTM和GRU的对比

**共同点：都能通过各种Gate保留重要特征，保证其在长期传播过程中不会丢失**

| LSTM                               | GRU（更新版）                                               |
| ---------------------------------- | ----------------------------------------------------------- |
| 具有三个们：输入门、输出门、遗忘门 | 具有两个门：重置门和更新门                                  |
| 。。。                             | GRU有更少的门，少做几次矩阵乘法，在多数据上节省了时间       |
| 。。。                             | GRU去掉了记忆细胞，直接通过隐藏状态传递信息，减少了参数变量 |

------------

### 6、序列到序列

#### Encoder和decoder

* Encoder：将现实问题转化为数学问题。如输入文字图片音频，转化为向量
* decoder：求解数学问题，得到现实世界的解决方案。如将向量等转为现实世界的文字图片音频

![image-20211223210530101](https://rossetta-typora-imgsubmit.oss-cn-hangzhou.aliyuncs.com/img/image-20211223210530101.png)

BOS：begin of sentence symbol

EOS：end of sentence symbol

![image-20211223210641489](https://rossetta-typora-imgsubmit.oss-cn-hangzhou.aliyuncs.com/img/image-20211223210641489.png)

1. 编码处理过程中，隐藏层的状态为$h(t) = f(h_t - 1, x_t)$
2. 每次获取隐藏层状态后，信息被总结并产出最终的语义代码$c = q(\{f(h_1, ..., h_{T_x})\})$
3. 解码阶段，我们解码$c$并产生输出序列$y_1, y_2, ...$来预测下个输出单词。以及产生的序列$y = \{y_1, y_2, ..., y_T\}$的条件概率

$$
p(y) = \prod_{t=1}^T p(y_t | \{y1, y2, ..., y_{t-1}\},c)
$$

4. g表示一个非线性变换，输出的是$y_t$的可能性

![image-20211223222202558](https://rossetta-typora-imgsubmit.oss-cn-hangzhou.aliyuncs.com/img/image-20211223222202558.png)

---------

### 7、注意力机制

> 为了计算输入数据对输出数据的贡献大小
>

-------

## 六、强化学习

> * 从交互中学习
> * 面向目标的学习
> * 当和外界的目标交互时，从中学习
> * 学习如何映射行动和情况来最大化数字奖励信号

![image-20211223225117270](https://rossetta-typora-imgsubmit.oss-cn-hangzhou.aliyuncs.com/img/image-20211223225117270.png)

![image-20211224104741221](https://rossetta-typora-imgsubmit.oss-cn-hangzhou.aliyuncs.com/img/image-20211224104741221.png)

训练数据：状态-行动的对子

目标函数：对奖励/惩罚进行评估，尽可能获得更大的reward，**最大化长期累积奖励**

输出：为action，在当前环境下采取的动作

强化学习同样是输入-输出的映射，不同的是，它不是分类图片和文本，而是**对智能体state value和action的描述**

状态：表示环境的数据，状态集是环境中所有可能的状态

策略：强化学习是从环境状态到动作的映射学习，该映射成为策略

### 1、蒙特卡洛和A2C

蒙特卡洛通过展开所有轨迹并计算每个state的reward来估计目标方案，而A2C则中途截断轨迹，靠计算critic来估计。

A2C的方案虽然会引入一些bias，但是它降低了估计的方差，同时允许不断的预测

----------

### 2、马尔可夫决策过程

具有马尔可夫性质的一系列时序状态满足如下公式：

![image-20211224105211843](https://rossetta-typora-imgsubmit.oss-cn-hangzhou.aliyuncs.com/img/image-20211224105211843.png)

即：**当前状态$S_t$已知时，<u>历史可以被忽略</u>**

满足马尔可夫性的随机时序状态$\{S_1, S_2, ..., S_n\}$称为马尔可夫过程，表示为$<S, P>$

其中，S为状态空间，P为状态转移概率矩阵

**从状态$S$转移到下一个状态$S'$的可能性被定义为$P_{SS'} = P[S_{t+1} = s'| S_t = s]$**

**状态转移矩阵**下标$ij$表示为从状态$s_i$转移到$s_j$：

![image-20211224110023307](https://rossetta-typora-imgsubmit.oss-cn-hangzhou.aliyuncs.com/img/image-20211224110023307.png)

**矩阵中每行之和为1**

#### 决策过程

马尔可夫决策过程是一个tuple $<S, A, P, R, \lambda>$

其中，S为状态集；A为动作集；P为状态转移函数（或矩阵），公式为：

![image-20211224110740181](https://rossetta-typora-imgsubmit.oss-cn-hangzhou.aliyuncs.com/img/image-20211224110740181.png)

R是奖励函数，表示为：

![image-20211224110808197](https://rossetta-typora-imgsubmit.oss-cn-hangzhou.aliyuncs.com/img/image-20211224110808197.png)

即时奖励可以表示为：

![image-20211224110940254](https://rossetta-typora-imgsubmit.oss-cn-hangzhou.aliyuncs.com/img/image-20211224110940254.png)

$\lambda$是一个折扣因子，在（0， 1）之间，总奖励可以表示为：

![image-20211224110908645](https://rossetta-typora-imgsubmit.oss-cn-hangzhou.aliyuncs.com/img/image-20211224110908645.png)

![image-20211224112319069](https://rossetta-typora-imgsubmit.oss-cn-hangzhou.aliyuncs.com/img/image-20211224112319069.png)

**决策矩阵**
$$
\pi (a|s) = P[A_t = a | S_t = s]
$$
表示当前状态下，采取不同策略的可能性，学习还是走神？

![image-20211224112157221](https://rossetta-typora-imgsubmit.oss-cn-hangzhou.aliyuncs.com/img/image-20211224112157221.png)

**状态价值函数$v_{\pi}(s)$和动作价值函数$q_{\pi}(s, a)$**寻找其最大值

![image-20211224112639754](https://rossetta-typora-imgsubmit.oss-cn-hangzhou.aliyuncs.com/img/image-20211224112639754.png)

