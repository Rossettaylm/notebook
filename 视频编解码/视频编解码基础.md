# 视频编解码基础

## 1、历史

在国际组织的独立和联合开发中，产生了很多重要的视频编解码标准。主要国际组织包括ISO/IEC MPEG、ITU-T、Google、Microsoft、AVS工作组和AOM联盟等。

**ITU-T，全称International Telecommunications Union - Telecommunication Standardization Sector，即国际电信联盟——电信标准分局。**该组织下设的VECG(Video Coding Experts Group)主要负责面向**实时通信领域**的标准制定，主要制定了H.261/H263/H263+/H263++等标准。

**ISO，全称International Standards Organization，即国际标准化组织。该组织下属的MPEG(Motion Picture Experts Group)，**即移动图像专家组主要负责**面向视频存储、广播电视、网络传输的视频标准**，主要制定了MPEG-1/MPEG-4等。

实际上，**真正在业界产生较强影响力的标准均是由两个组织合作产生的。比如MPEG-2、H.264/AVC和H.265/HEVC等。**

主要标准包括：JPEG、MJPEG、JPEG2000、H.261、MPEG-1、H.262/MPEG-2、H.263、MPEG-4 (Part2/ASP)、H.264/MPEG-4 (Part10/AVC)、H.265/MPEG-H (Part2/HEVC)、H.266/VVC、VP8/VP9、AV1、AVS1/AVS2、SVAC1/SVAC2等。

----------------------------------------

视频编解码器 [H.261](https://en.wikipedia.org/wiki/H.261) 诞生在 1990（技术上是 1988），被设计为以 **64 kbit/s 的数据速率**工作，提出了**混合编码模型**。它已经使用如色度子采样、宏块，等等理念。在 1995 年，**H.263** 视频编解码器标准被发布，并继续延续到 2001 年。

**MPEG-1**提出了IPB帧。解码时将恢复的图像存在缓存中，在显示时按顺序显示。

**MPEG-4**更注重于多媒体系统的可交互性和灵活性。

![image-20220527161501647](https://rossetta-typora-imgsubmit.oss-cn-hangzhou.aliyuncs.com/img/image-20220527161501647.png)

在 2003 年 **H.264/AVC** 的第一版被完成。在同一年，一家叫做 **TrueMotion** 的公司发布了他们的**免版税**有损视频压缩的视频编解码器，称为 **VP3**。在 2008 年，**Google 收购了**这家公司，在同一年发布 **VP8**。在 2012 年 12 月，Google 发布了 **VP9**，**市面上大约有 3/4 的浏览器**（包括手机）支持。

[AV1](https://en.wikipedia.org/wiki/AOMedia_Video_1) 是由 **Google, Mozilla, Microsoft, Amazon, Netflix, AMD, ARM, NVidia, Intel, Cisco** 等公司组成的[开放媒体联盟（AOMedia）](http://aomedia.org/)设计的一种新的免版税和开源的视频编解码器。**第一版** 0.1.0 参考编解码器**发布于 2016 年 4 月 7 号**。

[![编解码器历史线路图](https://rossetta-typora-imgsubmit.oss-cn-hangzhou.aliyuncs.com/img/codec_history_timeline.png)](https://github.com/leandromoreira/digital_video_introduction/blob/master/i/codec_history_timeline.png)

#### AV1 的诞生

2015 年早期，Google 正在开发VP10，Xiph (Mozilla) 正在开发Daala，Cisco 开源了其称为 Thor 的免版税视频编解码器。

接着 MPEG LA 宣布了 HEVC (H.265) 每年版税的的上限，比 H.264 高 8 倍，但很快他们又再次改变了条款：

- **不设年度收费上限**
- **收取内容费**（收入的 0.5%）
- **每单位费用高于 h264 的 10 倍**

[开放媒体联盟](http://aomedia.org/about/)由硬件厂商（Intel, AMD, ARM , Nvidia, Cisco），内容分发商（Google, Netflix, Amazon），浏览器维护者（Google, Mozilla），等公司创建。

这些公司有一个共同目标，一**个免版税的视频编解码器**，所以 AV1 诞生时使用了一个更[简单的专利许可证](http://aomedia.org/license/patent/)。

![image-20220526234805775](https://rossetta-typora-imgsubmit.oss-cn-hangzhou.aliyuncs.com/img/image-20220526234805775.png)

**FVC的编码性能已经比HEVC/H265提高了32%以上**

------------

## 2、通用编解码器的步骤

### 混合编码模型

![image-20220527004029042](https://rossetta-typora-imgsubmit.oss-cn-hangzhou.aliyuncs.com/img/image-20220527004029042.png)

当前输入的图像首先要经过分块，分块得到的图像块要与经过运动补偿的预测图像相减得到差值图像X，然后对该差值图像块进行DCT变换和量化，量化输出的数据有**两个不同的去处**：一个是送给熵编码器进行编码，编码后的码流输出到一个缓存器中保存，等待传送出去。另一个应用是进行反量化和反变化后的到信号X’，该信号将与运动补偿输出的图像块相加得到新的预测图像信号，并将新的预测图像块送至帧存储器。

- #### 分区 H264宏块（16x16）、H265（CTU）64x64~16x16

- #### 预测 
  
  - 帧内预测（空间）I帧
  - 帧间预测（时间）P帧、B帧 运动估计搜索得到运动矢量，由运动矢量得到的两图像块相减残差块叫做运动补偿
  
  运动估计技术一般将当前的输入图像**分割成若干彼此不相重叠的小图像子块**，然后在前一图像或者后一个图像某个搜索窗口的范围内**为每一个图像块寻找一个与之最为相似的图像块**。
  
  通过**计算最相似的图像块与该图像块之间的位置信息，可以得到一个运动矢量**。这样在编码过程中就可以将当前图像中的块与参考图像运动矢量所指向的最相似的图像块相减，得到一个残差图像块，由于残差图像块中的每个像素值很小，所以在压缩编码中可以获得更高的压缩比。**这个相减过程叫运动补偿**。
  
- #### 变换，将YUV分量变为频域中的分量，常见的正交变换方法有：K-L变换（性能最好但不易实现）、离散余弦变换(DCT)、离散正弦变换(DST)。
  
  - 将像素块转为相同大小的频率系数块
  - 压缩能量，消除空间冗余
  - 可逆变换
  
- #### 量化，选择性的剔除高频分量，保留对画质影响更大的低频分量，或者选择合适的量化矩阵

- #### 熵编码
  
  - VLC编码，可变长度编码，哈夫曼编码也是其中的一种（最优二叉树，每次将最小的两个权重节点作为左右子树），都是前缀编码
  - 算术编码，根据编码出现的概率划分不断的区间，最终由区间内的一个数可以得到算术编码
  - 具体来说主要有上下文自适应的变长编码(CAVLC)和上下文自适应的二进制算术编码(CABAC)

## H264

### 比特流格式

H264分为两层，包括了**NAL（Net Abstract Layer）网络抽象层和VCL（video code layer）视频编码层**，VCL包含了视频原始数据编码后的结果。

将压缩过的数据打包并发送，需要告诉解码器**编码定义**

**NAL（网络抽象层）**，提供网络友好的视频呈现方式，同步标记用来表示其边界，**NAL = Start Code + NAL header + RBSP（Raw Byte Sequence Payload）**。

![image-20220527001450661](https://rossetta-typora-imgsubmit.oss-cn-hangzhou.aliyuncs.com/img/image-20220527001450661.png)

![image-20220528221323529](https://rossetta-typora-imgsubmit.oss-cn-hangzhou.aliyuncs.com/img/image-20220528221323529.png)

<img src="https://rossetta-typora-imgsubmit.oss-cn-hangzhou.aliyuncs.com/img/image-20220529102128629.png" alt="image-20220529102128629" style="zoom:80%;" />

### H264帧内预测模式

![image-20220528223844430](https://rossetta-typora-imgsubmit.oss-cn-hangzhou.aliyuncs.com/img/image-20220528223844430.png)

**4x4亮度块：9种**

<img src="https://rossetta-typora-imgsubmit.oss-cn-hangzhou.aliyuncs.com/img/image-20220528223411487.png" alt="image-20220528223411487" style="zoom: 67%;" />

**16x16亮度预测模式：4种，8x8色度块预测模式：4种**

![image-20220528223628491](https://rossetta-typora-imgsubmit.oss-cn-hangzhou.aliyuncs.com/img/image-20220528223628491.png)

<img src="https://rossetta-typora-imgsubmit.oss-cn-hangzhou.aliyuncs.com/img/image-20220528223743079.png" alt="image-20220528223743079" style="zoom: 67%;" />



### H264帧间预测模式

**每个分割有独立的运动补偿**

![image-20220528232005976](https://rossetta-typora-imgsubmit.oss-cn-hangzhou.aliyuncs.com/img/image-20220528232005976.png)

### H264的解码过程

![image-20220529104633680](https://rossetta-typora-imgsubmit.oss-cn-hangzhou.aliyuncs.com/img/image-20220529104633680.png)

![image-20220529100557510](https://rossetta-typora-imgsubmit.oss-cn-hangzhou.aliyuncs.com/img/image-20220529100557510.png)

## AVS系列标准

AVS3视频基准档次采用了更具复杂视频内容适应性的扩展四叉树划分(EQT,Extended Quad-Tree)、更适合复杂运动形式的仿射运动预测、自适应运动矢量精度预测(AMVR, Adaptive Motion Vector Resolution)、更宜于并行编解码实现的片划分机制等技术，比AVS2节省约30%的码率，将帮助改善5G时代视频传输、虚拟现实直播与点播的用户体验，形成突破性的解决方案，为服务提供商和运营商节约大量成本，同时带来培育新商业模式的机会，具有重要的社会效益和经济效益。

![image-20220528183053938](https://rossetta-typora-imgsubmit.oss-cn-hangzhou.aliyuncs.com/img/image-20220528183053938.png)



## 3、H265/HEVC

**基于四叉树的块划分方法**

### 编码单元CU

H265将图像划分为**编码树单元（CTU）**，范围为**64x64, 32x32, 16x16**

每个编码树单元可以被递归分割成四叉树，最小的块是**编码单元（CU）**，64x64最多递归分割3次变成**8x8**，即**minimum size CU**，视频序列的分辨率要求是minimum size CU的倍数。

CU可以分为两类：跳过型CU（Skipped CU）和普通CU。

- 跳过型CU只能采用**帧间预测模式**，而且产生的运动向量和图像的残差信息（都是0）不需要传送给解码器；
- 普通CU则可以采用**帧内预测和帧间预测**两种方式进行预测，然后对残差数据以及附加的控制信息进行编码。

编码单元是H265基本的**预测单元**，CU是进行决策帧间、帧内、skip/merge的基本单元

**一个CTU包含一个Luma CTB和两个Chroma CTB**

### 预测单元PU

HECV在CU layer层决定**预测模式（prediction mode）**。根据不同的预测模式将CU分为

- 画面内编码单元（Intra Coded CU）：使用周围影响做重建的取样样本，**画面内预测**，允许**2种正方形的切割方法**

- 画面间编码单元（Inter Coded CU）：使用运动补偿做预测，**画面间预测**，允许**8种切割方法**

  - 矩形的切割方式共**4种**，分别为2Nx2N、NxN、2NxN及Nx2N。
  - 非对称切割方式共**4种**

  ![image-20220526230230133](https://rossetta-typora-imgsubmit.oss-cn-hangzhou.aliyuncs.com/img/image-20220526230230133.png)

#### Luma CB的预测

有**35个**可选的**帧内预测方向**

- Planar(0)
- DC(1)
- 方向预测(2~34)

NxN的划分方式（4块）只对minimum size CB有用

做帧内预测时，需要为Intra PU确认**最可能模式**集合，如果在其中用2bit表示，如果不在需要5bit在另外32种模式中找

#### Chroma CB的预测

有**5个**可选的**帧内预测方向**

- Planar/0、
- DC/1、
- Vertical/26、
- Horizontal/10
- luma PU的预测方向

对于**预测模式的编码**，通过0表示luma PU的预测方向，100、111、101和110分别表示Planar/0、DC/1、Vertical/26和Horizontal/10。

#### 帧间预测

根据两个参考表L0和L1来预测，每一个都有16个参考项，有两个主要的**预测模式**

- 合并（对应矩形的切割方式）
- 高级运动（对应非矩形的切割方式）

### 转换单元TU

转换单元是呈现**残量（Residual）**或者是**转换系数（Transform Coefficients）**的区块

主要做**整数转换（Integer Transform）**或者是**量化（Quantization）**

转换单元可以在编码单元CU的基础上继续的往下递归分割，**最小到达4x4**

转换单元TU的编码树CT可以称为转换树(Transform Tree)或是**残量四分树**(Residual Quadtree, **RQT**)。

## 5、介绍下264和265的区别

块划分：264是以宏块为单位，最大16x16；265是以CTU为单位，最大64x64；是为了适应更高分辨率的视频而增加了编码单元的尺寸，因为高清超高清这些具有更多平滑块；另外265增加了PU、TU，使得预测和变换分离开，使得模式选择能够更加适应块内内容。
预测：264的帧内预测只有9种（8角度+DC），而265增加到了35种（33角度+DC+planar）；
264运动估计采用基于预测子集的搜索算法，265运动估计新增TZSearch算法。
265帧间预测增加了MV的预测过程，包括merge和AMVP模式；
265新增一种无损编码模式——PCM模式，就是直接传输CU的像素值而不进行预测变换等操作。
变换：（1）变换尺寸有变化。264变换以4x4和16x16为主，8x8比较少用到； 265变换从4x4 ~ 32x32遍历；
（2）整数化时放大倍数有不同。264和265都是采用的整数DCT，但是264仅放大了2-3.16倍，265放大了128倍，更加接近浮点型DCT。
（3）增加了DST（适用于Luma4x4块，具体为什么，应该是实验试出来的？）
量化：量化步长有增加到52个，量化系数矩阵有所改进
熵编码：
后处理：新增SAO模块，解决量化造成的振铃效应。

## 5、FVC的发展

### 一、更灵活的图像划分

![image-20220526235054320](https://rossetta-typora-imgsubmit.oss-cn-hangzhou.aliyuncs.com/img/image-20220526235054320.png)

基于四叉树+**二叉树、三叉树的划分**

![image-20220526235156625](https://rossetta-typora-imgsubmit.oss-cn-hangzhou.aliyuncs.com/img/image-20220526235156625.png)

### 二、解码端运动矢量推导

### 三、基于仿射变换模型帧间预测技术

![image-20220526235547360](https://rossetta-typora-imgsubmit.oss-cn-hangzhou.aliyuncs.com/img/image-20220526235547360.png)

### 四、基于维纳滤波器的自适应滤波方法

![image-20220526235720312](https://rossetta-typora-imgsubmit.oss-cn-hangzhou.aliyuncs.com/img/image-20220526235720312.png)

--------------------

## 基于机器学习的编解码发展

![image-20220527000732561](https://rossetta-typora-imgsubmit.oss-cn-hangzhou.aliyuncs.com/img/image-20220527000732561.png)

- 如何依据视频的自身特性设计优化的编码方法？
- 衡量失真的指标均方误差（信号保真度）与重建视频的视觉质量并非一一对应，如何面向视觉质量优化来设计编码方法？

**CNN可以用于视频编码带来的人工痕迹和后处理**

![image-20220527000436151](https://rossetta-typora-imgsubmit.oss-cn-hangzhou.aliyuncs.com/img/image-20220527000436151.png)



## 面试题

### 1、块效应：

（1）概念：

主要是由视频图像采用基于块的编码方式和量化造成相邻块之间存在明显差异的现象，在[视频编码](https://so.csdn.net/so/search?q=视频编码&spm=1001.2101.3001.7020)中人眼察觉到的小块边界处的不连续。

（2）产生原因：

1、编码过程中对残差进行DCT变换是基于块的，使得块与块之间的相关性被忽略了；

2、对DCT系数进行量化，不同的图像块做了不同的处理。

（3）解决方案：

在视频编码中，为了解决或减小块效应，很多视频编码标准（H264，H265，SVAC）中采用了去块滤波Deblock的方案。

### 2、振铃效应：

（1）概念：

图像处理中，对一幅图像进行滤波处理，若选用的频域滤波器具有陡峭的变化，则会使滤波图像产生“振铃”，所谓“振铃”，就是指输出图像的灰度剧烈变化处产生的震荡，就好像钟被敲击后产生的空气震荡。

（2）产生原因：

主要是由于DCT变换后对高频分量进行滤波操作导致。

（3）解决方案：

在视频编码中，为了解决或减小振铃效应，H265和SVAC2中采用了SAO样点滤波偏移的方案。

### 3、呼吸效应：

（1）概念：

视频编码中的呼吸效应是指由于I帧的插入造成图像质量忽然变好，切换到P帧后又忽然变差。

一般情况下，我们都会将I帧调的比较大，一个GOP内，离I帧越远的P帧，编码误差越大，图像降质也越严重，当下一个I帧出现时，图像又立即变得清楚起来，纵观整个视频流，就会周期性出现清楚到模糊的突变，我们称这种现象为呼吸效应。

呼吸效应在静止的场景下比较容易观察出来，运动场景中，大部分的图像内容都在变化，不容易发现。

（2）分析：

呼吸效应在静止的场景下比较容易观察出来，运动场景中，大部分的图像内容都在变化，不容易发现。尤其在低码率的视频监控场景下，呼吸效应比较明显。

产生的主要原因：I帧和P帧的编码模式和编码质量的不同，导致视觉上图像不连续。

（3）解决方案：

一般情况下，CBR（固定码率）码控方式比CQP（固定QP）的呼吸效应更加严重。因此将码控模式修改为CQP方式在一定程度上可以减弱呼吸效应。
H264/5可以调节I帧P帧直接qp的偏差，控制I帧和P帧的大小比例关系，I帧的qp越小，I帧越大，图像越清楚，在一定程度上提升了整体图像质量，呼吸效应在一定程度上可以得到缓解；但是I帧也不能调的过大，在CBR模式下，I帧把全部带宽都吃掉了，P帧就只能编的更模糊一些，反而加重了呼吸效应；在实际调节过程中，就是通过调整intraQpDelta/intraQpOffset这类的参数来调节I帧大小；在ISP中，如果有3DSR功能，针对静止场景，可以有效改善呼吸效应。
HISI提出了前滤波编码的方案，基于HISI编码器的硬件实现，对I帧的编码数据进行滤波操作然后再编码，可以改善呼吸效应，对应MPI接口为HI_MPI_VENC_GetDeBreathEffect和HI_MPI_VENC_SetDeBreathEffect。

总结：
块效应：基于块的编码方式和量化造成相邻块之间存在明显差异的现象；
振铃效应：对图像进行滤波处理时，输出图像的灰度剧烈变化处产生的震荡，就好像钟被敲击后产生的空气震荡；
呼吸效应：一个GOP内，离I帧越远的P帧，编码误差越大，图像降质也越严重，当下一个I帧出现时，图像又立即变得清楚起来，纵观整个视频流，就会周期性出现清楚到模糊的突变。

### 评估指标

**PSNR**=$10*log10((2^{n-1}2/MSE) $（MSE是原图像与处理图像之间均⽅误差，所以计算PSNR需要2幅图像的数据！）

**SSIM** （结构相似性分别从亮度对⽐度、对⽐度、结构3⽅⾯度量图像的相似性）

-------------

## X264结构

### 1. 命令行程序

![img](https://rossetta-typora-imgsubmit.oss-cn-hangzhou.aliyuncs.com/img/20160304205713131)

x264_param_default()：设置参数集结构体x264_param_t的缺省值。

x264_encoder_open()：打开编码器。

x264_encoder_headers()：输出SPS，PPS，SEI等信息。

x264_encoder_encode()：编码输出一帧图像。

x264_encoder_close()：关闭编码器。

该程序的入口函数为main()。main()函数首先调用parse()解析输入的参数，然后调用encode()编码YUV数据。parse()首先调用x264_param_default()为保存参数的x264_param_t结构体赋默认值；然后在一个大循环中通过getopt_long()解析通过命令行传递来的存储在argv[]中的参数，并作相应的设置工作；最后调用select_input()和select_output()完成输入文件格式（yuv，y4m等）和输出文件格式（裸流，mp4，mkv，FLV等）的设置。encode()首先调用x264_encoder_open()打开编码器；接着在一个循环中反复调用encode_frame()一帧一帧地进行编码；最后在编码完成后调用x264_encoder_close()关闭编码器。encode_frame()则调用x264_encoder_encode()将存储YUV数据的x264_picture_t编码为存储H.264数据的x264_nal_t。

### 2.libx264类库的接口

![image-20220531001616209](https://rossetta-typora-imgsubmit.oss-cn-hangzhou.aliyuncs.com/img/image-20220531001616209.png)